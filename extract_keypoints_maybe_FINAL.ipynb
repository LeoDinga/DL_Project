{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDinga/DL_Project/blob/main/extract_keypoints_maybe_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33zp4ccr7b0"
      },
      "source": [
        "### Deep Learning Project: Action Recognition in Tennis\n",
        "Students: Diana Santos (64478), Leonor Fandinga (64481), Sofia Rocha (65111)\n",
        "\n",
        "Professor: Nuno Garcia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM30w6NLpUuh",
        "outputId": "36da5820-dd1f-4d4c-92d8-72b0cc945e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.7 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#Installs the libraries needed to extract the keypoints\n",
        "!pip install mediapipe opencv-python tqdm --upgrade\n",
        "\n",
        "#Restart the runtime to apply the changes\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyLRUvlxoG4B",
        "outputId": "8ca5ebb8-e91b-4573-8ab9-f7e6e106ee5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing actions: 100%|██████████| 12/12 [34:00<00:00, 170.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keypoints saved to all_keypoints.npz\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm\n",
        "\n",
        "#39 minutos\n",
        "\n",
        "def convert_video_to_npy(video_path, resize_shape=(224, 224)):\n",
        "    \"\"\"\n",
        "    Reads a video from the specified path, resizes each frame to the indicated size (default: (224, 224) ) and returns a NumPy array containing all the frames.\n",
        "\n",
        "    Parameters:\n",
        "        video_path (str): Path to the video file (.avi).\n",
        "        resize_shape (tuple): Size to resize each frame, (height, width). Default=(224, 224)\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, resize_shape)\n",
        "        frames.append(frame_resized)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def pad_or_truncate_keypoints(keypoints, target_length=120):\n",
        "    num_frames = keypoints.shape[0]\n",
        "    if num_frames < target_length:\n",
        "        padding = np.zeros((target_length - num_frames, keypoints.shape[1], keypoints.shape[2]))\n",
        "        return np.concatenate((keypoints, padding), axis=0)\n",
        "    else:\n",
        "        return keypoints[:target_length]\n",
        "\n",
        "def create_npy_from_videos(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "    for action in os.listdir(src_dir):\n",
        "        action_path = os.path.join(src_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "        dest_action_path = os.path.join(npy_dir, action)\n",
        "        os.makedirs(dest_action_path, exist_ok=True)\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if video_file.endswith(\".avi\"):\n",
        "                video_path = os.path.join(action_path, video_file)\n",
        "                output_path = os.path.join(dest_action_path, video_file.replace(\".avi\", \".npy\"))\n",
        "                try:\n",
        "                    frames_array = convert_video_to_npy(video_path)\n",
        "                    np.save(output_path, frames_array)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "def extract_keypoints_from_npy(npy_dir, save_path=\"all_keypoints.npz\"):\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose(static_image_mode=True)\n",
        "    all_keypoints = {}\n",
        "\n",
        "    for action in tqdm(os.listdir(npy_dir), desc=\"Processing actions\"):\n",
        "        action_path = os.path.join(npy_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "\n",
        "        all_keypoints[action] = {}\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if not video_file.endswith(\".npy\"):\n",
        "                continue\n",
        "            video_path = os.path.join(action_path, video_file)\n",
        "            try:\n",
        "                sample = np.load(video_path)\n",
        "                if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "                    continue\n",
        "                sample = sample.astype(np.uint8)\n",
        "\n",
        "                video_keypoints = []\n",
        "                for frame in sample[::5]:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results = pose.process(frame_rgb)\n",
        "                    if results.pose_landmarks:\n",
        "                        keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "                    else:\n",
        "                        keypoints = np.zeros((33, 3)).tolist()\n",
        "                    video_keypoints.append(keypoints)\n",
        "\n",
        "                if video_keypoints:\n",
        "                    kp_array = np.array(video_keypoints)\n",
        "                    kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "                    all_keypoints[action][video_file] = kp_array\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "    # Transformar em dicionário plano para salvar com np.savez_compressed\n",
        "    flat_dict = {}\n",
        "    for action, videos in all_keypoints.items():\n",
        "        for video_file, arr in videos.items():\n",
        "            key = f\"{action}__{video_file.replace('.npy', '')}\"\n",
        "            flat_dict[key] = arr\n",
        "\n",
        "    np.savez_compressed(save_path, **flat_dict)\n",
        "    print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Clone dataset se necessário\n",
        "    if not os.path.exists(\"dataset\"):\n",
        "        os.system(\"git clone --filter=blob:none --no-checkout https://github.com/THETIS-dataset/dataset.git\")\n",
        "        os.chdir(\"dataset\")\n",
        "        os.system(\"git sparse-checkout init --cone\")\n",
        "        os.system(\"git sparse-checkout set VIDEO_RGB\")\n",
        "        os.system(\"git checkout\")\n",
        "        os.chdir(\"..\")\n",
        "\n",
        "    src_dir = \"dataset/VIDEO_RGB\"\n",
        "    npy_dir = \"npy_videos\"\n",
        "    create_npy_from_videos(src_dir, npy_dir)\n",
        "    extract_keypoints_from_npy(npy_dir, save_path=\"all_keypoints.npz\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe0IeYuDLT05"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}