{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDinga/DL_Project/blob/main/extract_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33zp4ccr7b0"
      },
      "source": [
        "# Deep Learning Project: Action Recognition in Tennis\n",
        "Students: Diana Santos (64478), Leonor Fandinga (64481), Sofia Rocha (65111)\n",
        "\n",
        "Professor: Nuno Garcia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM30w6NLpUuh",
        "outputId": "9e1ae4ba-97f3-4175-fcb2-7a5980e4115b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#Installs the libraries needed to extract the keypoints\n",
        "!pip install mediapipe opencv-python tqdm --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Before executing the next code cell, the Google Colab runtime must be restarted."
      ],
      "metadata": {
        "id": "30jeaUkv_GTA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyLRUvlxoG4B",
        "outputId": "99a38823-c8c9-4c21-a50b-d3671fddc19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing actions: 100%|██████████| 12/12 [24:13<00:00, 121.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints saved to all_keypoints.npz\n"
          ]
        }
      ],
      "source": [
        "#Execution time: 33 min\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp #\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_video_to_npy(video_path, resize_shape=(224, 224)):\n",
        "    \"\"\"\n",
        "    Reads a video frame by frame from the specified path, resizes each frame to the indicated size (default: (224, 224) )\n",
        "    and returns a NumPy array containing all the frames.\n",
        "\n",
        "    Parameters:\n",
        "        video_path (str): Path to the video file (.avi).\n",
        "        resize_shape (tuple): Size to resize each frame, (height, width). Default=(224, 224)\n",
        "\n",
        "    Note: In the end the video is saved as an .npy file, containing all the frames converted into image arrays.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, resize_shape)\n",
        "        frames.append(frame_resized)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def create_npy_from_videos(src_dir, npy_dir):\n",
        "    \"\"\"\n",
        "    For each video in a source directory, converts the video into a NumPy array of frames\n",
        "    (using the secundary function convert_video_to_npy) and saves each array as a .npy file\n",
        "    in a destination directory, organising them by class/action.\n",
        "\n",
        "    Parameters:\n",
        "        rc_dir (str): Path to the source directory containing subfolders of videos by action.\n",
        "        npy_dir (str): Path to the destination directory, where the .npy arrays will be saved.\n",
        "    \"\"\"\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "    for action in os.listdir(src_dir):\n",
        "        action_path = os.path.join(src_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "        dest_action_path = os.path.join(npy_dir, action)\n",
        "        os.makedirs(dest_action_path, exist_ok=True)\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if video_file.endswith(\".avi\"):\n",
        "                video_path = os.path.join(action_path, video_file)\n",
        "                output_path = os.path.join(dest_action_path, video_file.replace(\".avi\", \".npy\"))\n",
        "                try:\n",
        "                    frames_array = convert_video_to_npy(video_path)\n",
        "                    np.save(output_path, frames_array)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "def pad_or_truncate_keypoints(keypoints, target_length=120):\n",
        "    \"\"\"\n",
        "    Sets the number of keypoint frames to a fixed size (default: 120).\n",
        "    If there are fewer frames than the target, fill with zeros (pad); if there are more, cut (truncate).\n",
        "\n",
        "    Parameters:\n",
        "        keypoints (np.ndarray): array of keypoints with shape (num_frames, num_points, 3).\n",
        "        target_length (int): Desired number of frames in the output.\n",
        "\n",
        "    Note: Each frame of the video was converted into a NumPy array representing the image.\n",
        "    \"\"\"\n",
        "    num_frames = keypoints.shape[0]\n",
        "    if num_frames < target_length:\n",
        "        padding = np.zeros((target_length - num_frames, keypoints.shape[1], keypoints.shape[2]))\n",
        "        return np.concatenate((keypoints, padding), axis=0)\n",
        "    else:\n",
        "        return keypoints[:target_length]\n",
        "\n",
        "def extract_keypoints_from_npy(npy_dir, save_path=\"all_keypoints.npz\"):\n",
        "    \"\"\"\n",
        "    Extracts pose keypoints from videos stored in .npy arrays using the MediaPipe library and saves them as .npz files.\n",
        "\n",
        "    Parameters:\n",
        "        npy_dir (str): Directory containing .npy arrays of videos organised by action.\n",
        "        save_path (str): Path of the output .npz file, where it will be saved.\n",
        "    \"\"\"\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose(static_image_mode=True)\n",
        "    all_keypoints = {}\n",
        "\n",
        "    for action in tqdm(os.listdir(npy_dir), desc=\"Processing actions\"):\n",
        "        action_path = os.path.join(npy_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "\n",
        "        all_keypoints[action] = {}\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if not video_file.endswith(\".npy\"):\n",
        "                continue\n",
        "            video_path = os.path.join(action_path, video_file)\n",
        "            try:\n",
        "                sample = np.load(video_path)\n",
        "                if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "                    continue\n",
        "                sample = sample.astype(np.uint8)\n",
        "\n",
        "                video_keypoints = []\n",
        "                for frame in sample[::5]:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results = pose.process(frame_rgb)\n",
        "                    if results.pose_landmarks:\n",
        "                        keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "                    else:\n",
        "                        keypoints = np.zeros((33, 3)).tolist()\n",
        "                    video_keypoints.append(keypoints)\n",
        "\n",
        "                if video_keypoints:\n",
        "                    kp_array = np.array(video_keypoints)\n",
        "                    kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "                    all_keypoints[action][video_file] = kp_array\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "    #Transform into a simple dictionary to save arrays with np.savez_compressed\n",
        "    flat_dict = {}\n",
        "    for action, videos in all_keypoints.items():\n",
        "        for video_file, arr in videos.items():\n",
        "            #key: concatenation of the action name with the video name\n",
        "            key = f\"{action}__{video_file.replace('.npy', '')}\"\n",
        "\n",
        "            #value: the corresponding keypoint array\n",
        "            flat_dict[key] = arr\n",
        "\n",
        "    np.savez_compressed(save_path, **flat_dict)\n",
        "    print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# Clone dataset if necessary\n",
        "if not os.path.exists(\"dataset/VIDEO_RGB\"):\n",
        "    os.system(\"git clone --filter=blob:none --no-checkout https://github.com/THETIS-dataset/dataset.git\")\n",
        "    os.chdir(\"dataset\")\n",
        "    os.system(\"git sparse-checkout init --cone\")\n",
        "    os.system(\"git sparse-checkout set VIDEO_RGB\")\n",
        "    os.system(\"git checkout\")\n",
        "    os.chdir(\"..\")\n",
        "\n",
        "src_dir = \"dataset/VIDEO_RGB\"\n",
        "npy_dir = \"npy_videos\"\n",
        "create_npy_from_videos(src_dir, npy_dir)\n",
        "extract_keypoints_from_npy(npy_dir, save_path=\"all_keypoints.npz\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}