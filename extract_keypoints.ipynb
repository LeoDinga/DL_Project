{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDinga/DL_Project/blob/main/extract_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python tqdm --upgrade\n",
        "import os\n",
        "# os.kill(os.getpid(), 9)  # Reinicia o runtime para aplicar as mudanças"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM30w6NLpUuh",
        "outputId": "823187d8-9a1c-4931-c679-0b99c6a2f784"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/LeoDinga/DL_Project.git\n",
        "%cd DL_Project\n"
      ],
      "metadata": {
        "id": "QpT9Hqfrb1Q6",
        "outputId": "6e516e9a-b817-4568-9dbe-878dd5fcf658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DL_Project' already exists and is not an empty directory.\n",
            "/content/DL_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyLRUvlxoG4B",
        "outputId": "50bb949c-7f29-43d0-a832-1d9c68205136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: VID-20250526-WA0005.mp4\n",
            "Processing: VID-20250526-WA0001.mp4\n",
            "Processing: VID-20250526-WA0002.mp4\n",
            "Processing: VID-20250526-WA0009.mp4\n",
            "Processing: VID-20250526-WA0008.mp4\n",
            "Processing: VID-20250526-WA0012.mp4\n",
            "Processing: VID-20250526-WA0007.mp4\n",
            "Processing: VID-20250526-WA0010.mp4\n",
            "Processing: VID-20250526-WA0011.mp4\n",
            "Processing: VID-20250526-WA0006.mp4\n",
            "Processing: VID-20250526-WA0004.mp4\n",
            "Processing: VID-20250526-WA0003.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing videos: 100%|██████████| 36/36 [01:55<00:00,  3.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints saved to our_keypoints.npz\n"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "def convert_video_to_npy(video_path, resize_shape=(224, 224)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, resize_shape)\n",
        "        frames.append(frame_resized)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def create_npy_from_videos_flat(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "\n",
        "    for video_file in os.listdir(src_dir):\n",
        "        if not video_file.lower().endswith((\".mp4\", \".avi\")):\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(src_dir, video_file)\n",
        "        output_path = os.path.join(npy_dir, video_file.replace(\".mp4\", \".npy\").replace(\".avi\", \".npy\"))\n",
        "\n",
        "        try:\n",
        "            print(f\"Processing: {video_file}\")\n",
        "            frames_array = convert_video_to_npy(video_path)\n",
        "            np.save(output_path, frames_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "\n",
        "def pad_or_truncate_keypoints(keypoints, target_length=120):\n",
        "    num_frames = keypoints.shape[0]\n",
        "    if num_frames < target_length:\n",
        "        padding = np.zeros((target_length - num_frames, keypoints.shape[1], keypoints.shape[2]))\n",
        "        return np.concatenate((keypoints, padding), axis=0)\n",
        "    else:\n",
        "        return keypoints[:target_length]\n",
        "\n",
        "def create_npy_from_videos(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "    for action in os.listdir(src_dir):\n",
        "        action_path = os.path.join(src_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "        dest_action_path = os.path.join(npy_dir, action)\n",
        "        os.makedirs(dest_action_path, exist_ok=True)\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if file.endswith((\".avi\", \".mp4\")):\n",
        "                video_path = os.path.join(action_path, video_file)\n",
        "                output_path = os.path.join(dest_action_path, video_file.replace(\".avi\", \".npy\"))\n",
        "                try:\n",
        "                    frames_array = convert_video_to_npy(video_path)\n",
        "                    np.save(output_path, frames_array)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "def extract_keypoints_from_npy(npy_dir, save_path=\"our_keypoints.npz\"):\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose(static_image_mode=True)\n",
        "    all_keypoints = {}\n",
        "\n",
        "    for action in tqdm(os.listdir(npy_dir), desc=\"Processing actions\"):\n",
        "        action_path = os.path.join(npy_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "\n",
        "        all_keypoints[action] = {}\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if not video_file.endswith(\".npy\"):\n",
        "                continue\n",
        "            video_path = os.path.join(action_path, video_file)\n",
        "            try:\n",
        "                sample = np.load(video_path)\n",
        "                if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "                    continue\n",
        "                sample = sample.astype(np.uint8)\n",
        "\n",
        "                video_keypoints = []\n",
        "                for frame in sample[:]:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results = pose.process(frame_rgb)\n",
        "                    if results.pose_landmarks:\n",
        "                        keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "                    else:\n",
        "                        keypoints = np.zeros((33, 3)).tolist()\n",
        "                    video_keypoints.append(keypoints)\n",
        "\n",
        "                if video_keypoints:\n",
        "                    kp_array = np.array(video_keypoints)\n",
        "                    kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "                    all_keypoints[action][video_file] = kp_array\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "    # Transformar em dicionário plano para salvar com np.savez_compressed\n",
        "    flat_dict = {}\n",
        "    for action, videos in all_keypoints.items():\n",
        "        for video_file, arr in videos.items():\n",
        "            key = f\"{action}__{video_file.replace('.npy', '')}\"\n",
        "            flat_dict[key] = arr\n",
        "\n",
        "    np.savez_compressed(save_path, **flat_dict)\n",
        "    print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "def extract_keypoints_from_npy_flat(npy_dir, save_path=\"our_keypoints.npz\"):\n",
        "\n",
        "  mp_pose = mp.solutions.pose\n",
        "  pose = mp_pose.Pose(\n",
        "      static_image_mode=False,\n",
        "      min_detection_confidence=0.3,\n",
        "      min_tracking_confidence=0.3\n",
        "  )\n",
        "\n",
        "  all_keypoints = {}\n",
        "\n",
        "  for video_file in tqdm(os.listdir(npy_dir), desc=\"Processing videos\"):\n",
        "      if not video_file.endswith(\".npy\"):\n",
        "          continue\n",
        "      video_path = os.path.join(npy_dir, video_file)\n",
        "      try:\n",
        "          sample = np.load(video_path)\n",
        "          if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "              print(f\"Skipping {video_file}, unexpected shape {sample.shape}\")\n",
        "              continue\n",
        "          sample = sample.astype(np.uint8)\n",
        "\n",
        "          video_keypoints = []\n",
        "          for frame in sample:\n",
        "              frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "              results = pose.process(frame_rgb)\n",
        "              if results.pose_landmarks:\n",
        "                  keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "              else:\n",
        "                  keypoints = np.zeros((33, 3)).tolist()\n",
        "              video_keypoints.append(keypoints)\n",
        "\n",
        "          if video_keypoints:\n",
        "              kp_array = np.array(video_keypoints)\n",
        "              kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "              kp_array = np.expand_dims(kp_array, axis=1)\n",
        "              key = video_file.replace(\".npy\", \"\")\n",
        "              all_keypoints[key] = kp_array\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "  np.savez_compressed(save_path, **all_keypoints)\n",
        "  print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Clone dataset se necessário\n",
        "#     if not os.path.exists(\"dataset\"):\n",
        "#         os.system(\"git clone --filter=blob:none --no-checkout https://github.com/THETIS-dataset/dataset.git\")\n",
        "#         os.chdir(\"dataset\")\n",
        "#         os.system(\"git sparse-checkout init --cone\")\n",
        "#         os.system(\"git sparse-checkout set VIDEO_RGB\")\n",
        "#         os.system(\"git checkout\")\n",
        "#         os.chdir(\"..\")\n",
        "\n",
        "src_dir = \"/content/DL_Project/DL_Project/our_videos\"\n",
        "npy_dir = \"npy_videos\"\n",
        "\n",
        "create_npy_from_videos_flat(src_dir, npy_dir)\n",
        "extract_keypoints_from_npy_flat(npy_dir, save_path=\"our_keypoints.npz\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_root = \"/content/DL_Project/DL_Project/our_videos\"\n",
        "print(\"Contents of root video folder:\")\n",
        "print(os.listdir(video_root))"
      ],
      "metadata": {
        "id": "8mSuJtuqmKK1",
        "outputId": "6e863c4e-2699-4639-877e-99d61dbee3f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of root video folder:\n",
            "['VID-20250526-WA0005.mp4', 'VID-20250526-WA0001.mp4', 'VID-20250526-WA0002.mp4', 'VID-20250526-WA0009.mp4', 'VID-20250526-WA0008.mp4', 'VID-20250526-WA0012.mp4', 'VID-20250526-WA0007.mp4', 'VID-20250526-WA0010.mp4', 'VID-20250526-WA0011.mp4', 'VID-20250526-WA0006.mp4', 'VID-20250526-WA0004.mp4', 'VID-20250526-WA0003.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load keypoints\n",
        "keypoints_path = \"/content/DL_Project/our_keypoints.npz\"\n",
        "data = np.load(keypoints_path)\n",
        "\n",
        "# Rebuild dictionary\n",
        "all_keypoints = {}\n",
        "for key in data.files:\n",
        "    action, video_file = key.split(\"__\", 1)\n",
        "    if action not in all_keypoints:\n",
        "        all_keypoints[action] = {}\n",
        "    all_keypoints[action][video_file] = data[key]\n",
        "\n",
        "# Select one example\n",
        "first_action = list(all_keypoints.keys())[0]\n",
        "first_video = list(all_keypoints[first_action].keys())[0]\n",
        "frame_idx = 0\n",
        "\n",
        "points = all_keypoints[first_action][first_video][frame_idx]  # shape: (num_joints, 3)\n",
        "\n",
        "# === Define anatomical connections and colors ===\n",
        "anatomical_connections = {\n",
        "    'head': [\n",
        "        (0, 1), (1, 2), (2, 3),\n",
        "        (0, 4), (4, 5), (5, 6),\n",
        "        (3, 7), (6, 8),\n",
        "        (0, 9), (9, 10)\n",
        "    ],\n",
        "    'left_arm': [(11, 13), (13, 15), (15, 17), (15, 19), (15, 21)],\n",
        "    'right_arm': [(12, 14), (14, 16), (16, 18), (16, 20), (16, 22)],\n",
        "    'torso': [(11, 12), (23, 24), (11, 23), (12, 24)],\n",
        "    'left_leg': [(23, 25), (25, 27), (27, 29), (29, 31)],\n",
        "    'right_leg': [(24, 26), (26, 28), (28, 30), (30, 32)],\n",
        "}\n",
        "\n",
        "colors = {\n",
        "    'head': 'gray',\n",
        "    'left_arm': 'red',\n",
        "    'right_arm': 'blue',\n",
        "    'torso': 'orange',\n",
        "    'left_leg': 'green',\n",
        "    'right_leg': 'purple',\n",
        "}\n",
        "\n",
        "# === Plotting ===\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='black', s=20)\n",
        "\n",
        "for part, connections in anatomical_connections.items():\n",
        "    for i, j in connections:\n",
        "        if i < len(points) and j < len(points):  # ensure valid index\n",
        "            ax.plot(\n",
        "                [points[i, 0], points[j, 0]],\n",
        "                [points[i, 1], points[j, 1]],\n",
        "                [points[i, 2], points[j, 2]],\n",
        "                color=colors[part], linewidth=2\n",
        "            )\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title(f\"3D Skeleton - Frame {frame_idx} - {first_video}\")\n",
        "ax.view_init(elev=20, azim=-70)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IUkWt7Mtnpxz",
        "outputId": "fb3b74c5-d746-44fe-d69e-c1bcea849460"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0f3e6c996f4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mall_keypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_keypoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mall_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "ntu_joints_in_mediapipe = [\n",
        "    0, 11, 12, 13, 14, 15, 16,\n",
        "    23, 24, 25, 26, 27, 28,\n",
        "    5, 2, 7, 8,\n",
        "    17, 18, 19, 20, 21, 22,\n",
        "    29, 30\n",
        "]\n",
        "\n",
        "def filter_to_ntu_joints(keypoints): # keypoints (T, 33, C)\n",
        "    return keypoints[:, ntu_joints_in_mediapipe, :]\n",
        "\n",
        "def prepare_stgcn_data(dataset, label_map):\n",
        "    data_list = []\n",
        "    for i, (keypoints, action_name) in enumerate(dataset):\n",
        "        keypoints = np.array(keypoints)  # (T, 33, C)\n",
        "        keypoints = filter_to_ntu_joints(keypoints)  # (T, 25, C)\n",
        "        num_frames, num_joints, channels = keypoints.shape\n",
        "        keypoints = keypoints[np.newaxis, ...]  # add person dim: (M=1, T, V, C)\n",
        "\n",
        "        sample = {\n",
        "            'frame_dir': f'sample_{i}',\n",
        "            'label': label_map[action_name],\n",
        "            'img_shape': None,\n",
        "            'total_frames': num_frames,\n",
        "            'keypoint': keypoints,\n",
        "        }\n",
        "        data_list.append(sample)\n",
        "    return data_list\n",
        "\n",
        "# Load your data\n",
        "data_npz = np.load(\"our_keypoints.npz\")\n",
        "dataset = []\n",
        "\n",
        "for key in data_npz.files:\n",
        "    keypoints = data_npz[key]\n",
        "    if keypoints.ndim == 4 and keypoints.shape[1] == 1:\n",
        "        keypoints = np.squeeze(keypoints, axis=1)\n",
        "    dataset.append((keypoints, \"unknown\"))\n",
        "\n",
        "label_map = {\"unknown\": 0}\n",
        "test_data = prepare_stgcn_data(dataset, label_map)\n",
        "\n",
        "with open(\"our_test_labels.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_data, f)\n",
        "\n",
        "print(f\"Created our_test_labels.pkl with {len(test_data)} samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPRqOJOPvvxx",
        "outputId": "a5043695-1a36-4f8c-a3d2-f78c8ee3221d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created our_test_labels.pkl with 36 samples.\n"
          ]
        }
      ]
    }
  ]
}