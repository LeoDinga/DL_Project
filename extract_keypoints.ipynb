{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDinga/DL_Project/blob/main/extract_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python tqdm --upgrade\n",
        "import os\n",
        "# os.kill(os.getpid(), 9)  # Reinicia o runtime para aplicar as mudanças"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM30w6NLpUuh",
        "outputId": "c2841149-dd0f-4413-864e-a296956d7303"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.7)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/LeoDinga/DL_Project.git\n",
        "%cd DL_Project\n"
      ],
      "metadata": {
        "id": "QpT9Hqfrb1Q6",
        "outputId": "c048e0d5-bf2d-4188-db0c-e064c03132e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_Project'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 239 (delta 36), reused 1 (delta 1), pack-reused 130 (from 1)\u001b[K\n",
            "Receiving objects: 100% (239/239), 34.45 MiB | 19.07 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n",
            "/content/DL_Project/DL_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyLRUvlxoG4B",
        "outputId": "29353cce-e214-422d-9b3d-3632666206f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: VID-20250516-WA0030.mp4\n",
            "Processing: VID-20250516-WA0049.mp4\n",
            "Processing: WhatsApp Video 2025-05-26 at 22.02.04_d1dc8839.mp4\n",
            "Processing: VID-20250516-WA0048.mp4\n",
            "Processing: VID-20250516-WA0021.mp4\n",
            "Processing: VID-20250516-WA0003.mp4\n",
            "Processing: VID-20250516-WA0036.mp4\n",
            "Processing: VID-20250516-WA0008.mp4\n",
            "Processing: VID-20250516-WA0017.mp4\n",
            "Processing: VID-20250516-WA0027.mp4\n",
            "Processing: WhatsApp Video 2025-05-26 at 22.02.19_e1dffb53.mp4\n",
            "Processing: VID-20250516-WA0033.mp4\n",
            "Processing: VID-20250516-WA0026.mp4\n",
            "Processing: VID-20250516-WA0011.mp4\n",
            "Processing: VID-20250516-WA0009.mp4\n",
            "Processing: VID-20250516-WA0014.mp4\n",
            "Processing: VID-20250516-WA0022.mp4\n",
            "Processing: VID-20250516-WA0051.mp4\n",
            "Processing: VID-20250516-WA0018.mp4\n",
            "Processing: VID-20250516-WA0016.mp4\n",
            "Processing: WhatsApp Video 2025-05-26 at 22.02.23_80f85037.mp4\n",
            "Processing: VID-20250516-WA0012.mp4\n",
            "Processing: VID-20250516-WA0023.mp4\n",
            "Processing: VID-20250516-WA0019.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing actions: 100%|██████████| 36/36 [00:00<00:00, 83147.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints saved to our_keypoints.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from tqdm import tqdm\n",
        "#39 minutos\n",
        "\n",
        "def convert_video_to_npy(video_path, resize_shape=(224, 224)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, resize_shape)\n",
        "        frames.append(frame_resized)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def create_npy_from_videos_flat(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "\n",
        "    for video_file in os.listdir(src_dir):\n",
        "        if not video_file.lower().endswith((\".mp4\", \".avi\")):\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(src_dir, video_file)\n",
        "        output_path = os.path.join(npy_dir, video_file.replace(\".mp4\", \".npy\").replace(\".avi\", \".npy\"))\n",
        "\n",
        "        try:\n",
        "            print(f\"Processing: {video_file}\")\n",
        "            frames_array = convert_video_to_npy(video_path)\n",
        "            np.save(output_path, frames_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "\n",
        "def pad_or_truncate_keypoints(keypoints, target_length=120):\n",
        "    num_frames = keypoints.shape[0]\n",
        "    if num_frames < target_length:\n",
        "        padding = np.zeros((target_length - num_frames, keypoints.shape[1], keypoints.shape[2]))\n",
        "        return np.concatenate((keypoints, padding), axis=0)\n",
        "    else:\n",
        "        return keypoints[:target_length]\n",
        "\n",
        "def create_npy_from_videos(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "    for action in os.listdir(src_dir):\n",
        "        action_path = os.path.join(src_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "        dest_action_path = os.path.join(npy_dir, action)\n",
        "        os.makedirs(dest_action_path, exist_ok=True)\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if file.endswith((\".avi\", \".mp4\")):\n",
        "                video_path = os.path.join(action_path, video_file)\n",
        "                output_path = os.path.join(dest_action_path, video_file.replace(\".avi\", \".npy\"))\n",
        "                try:\n",
        "                    frames_array = convert_video_to_npy(video_path)\n",
        "                    np.save(output_path, frames_array)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "def extract_keypoints_from_npy(npy_dir, save_path=\"our_keypoints.npz\"):\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose(static_image_mode=True)\n",
        "    all_keypoints = {}\n",
        "\n",
        "    for action in tqdm(os.listdir(npy_dir), desc=\"Processing actions\"):\n",
        "        action_path = os.path.join(npy_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "\n",
        "        all_keypoints[action] = {}\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if not video_file.endswith(\".npy\"):\n",
        "                continue\n",
        "            video_path = os.path.join(action_path, video_file)\n",
        "            try:\n",
        "                sample = np.load(video_path)\n",
        "                if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "                    continue\n",
        "                sample = sample.astype(np.uint8)\n",
        "\n",
        "                video_keypoints = []\n",
        "                for frame in sample[::5]:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results = pose.process(frame_rgb)\n",
        "                    if results.pose_landmarks:\n",
        "                        keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "                    else:\n",
        "                        keypoints = np.zeros((33, 3)).tolist()\n",
        "                    video_keypoints.append(keypoints)\n",
        "\n",
        "                if video_keypoints:\n",
        "                    kp_array = np.array(video_keypoints)\n",
        "                    kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "                    all_keypoints[action][video_file] = kp_array\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "    # Transformar em dicionário plano para salvar com np.savez_compressed\n",
        "    flat_dict = {}\n",
        "    for action, videos in all_keypoints.items():\n",
        "        for video_file, arr in videos.items():\n",
        "            key = f\"{action}__{video_file.replace('.npy', '')}\"\n",
        "            flat_dict[key] = arr\n",
        "\n",
        "    np.savez_compressed(save_path, **flat_dict)\n",
        "    print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Clone dataset se necessário\n",
        "#     if not os.path.exists(\"dataset\"):\n",
        "#         os.system(\"git clone --filter=blob:none --no-checkout https://github.com/THETIS-dataset/dataset.git\")\n",
        "#         os.chdir(\"dataset\")\n",
        "#         os.system(\"git sparse-checkout init --cone\")\n",
        "#         os.system(\"git sparse-checkout set VIDEO_RGB\")\n",
        "#         os.system(\"git checkout\")\n",
        "#         os.chdir(\"..\")\n",
        "\n",
        "src_dir = \"/content/DL_Project/DL_Project/our_videos_b\"\n",
        "npy_dir = \"npy_videos\"\n",
        "\n",
        "create_npy_from_videos_flat(src_dir, npy_dir)\n",
        "extract_keypoints_from_npy(npy_dir, save_path=\"our_keypoints.npz\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_root = \"/content/DL_Project/DL_Project/our_videos\"\n",
        "print(\"Contents of root video folder:\")\n",
        "print(os.listdir(video_root))"
      ],
      "metadata": {
        "id": "8mSuJtuqmKK1",
        "outputId": "226a84ef-ba88-41f4-a45c-30b0cee914b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of root video folder:\n",
            "['VID-20250526-WA0005.mp4', 'VID-20250526-WA0001.mp4', 'VID-20250526-WA0002.mp4', 'VID-20250526-WA0009.mp4', 'VID-20250526-WA0008.mp4', 'VID-20250526-WA0012.mp4', 'VID-20250526-WA0007.mp4', 'VID-20250526-WA0010.mp4', 'VID-20250526-WA0011.mp4', 'VID-20250526-WA0006.mp4', 'VID-20250526-WA0004.mp4', 'VID-20250526-WA0003.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load keypoints\n",
        "keypoints_path = \"/content/DL_Project/DL_Project/our_keypoints.npz\"\n",
        "data = np.load(keypoints_path)\n",
        "\n",
        "# Rebuild dictionary\n",
        "all_keypoints = {}\n",
        "for key in data.files:\n",
        "    action, video_file = key.split(\"__\", 1)\n",
        "    if action not in all_keypoints:\n",
        "        all_keypoints[action] = {}\n",
        "    all_keypoints[action][video_file] = data[key]\n",
        "\n",
        "# Select one example\n",
        "first_action = list(all_keypoints.keys())[0]\n",
        "first_video = list(all_keypoints[first_action].keys())[0]\n",
        "frame_idx = 0\n",
        "\n",
        "points = all_keypoints[first_action][first_video][frame_idx]  # shape: (num_joints, 3)\n",
        "\n",
        "# === Define anatomical connections and colors ===\n",
        "anatomical_connections = {\n",
        "    'head': [\n",
        "        (0, 1), (1, 2), (2, 3),\n",
        "        (0, 4), (4, 5), (5, 6),\n",
        "        (3, 7), (6, 8),\n",
        "        (0, 9), (9, 10)\n",
        "    ],\n",
        "    'left_arm': [(11, 13), (13, 15), (15, 17), (15, 19), (15, 21)],\n",
        "    'right_arm': [(12, 14), (14, 16), (16, 18), (16, 20), (16, 22)],\n",
        "    'torso': [(11, 12), (23, 24), (11, 23), (12, 24)],\n",
        "    'left_leg': [(23, 25), (25, 27), (27, 29), (29, 31)],\n",
        "    'right_leg': [(24, 26), (26, 28), (28, 30), (30, 32)],\n",
        "}\n",
        "\n",
        "colors = {\n",
        "    'head': 'gray',\n",
        "    'left_arm': 'red',\n",
        "    'right_arm': 'blue',\n",
        "    'torso': 'orange',\n",
        "    'left_leg': 'green',\n",
        "    'right_leg': 'purple',\n",
        "}\n",
        "\n",
        "# === Plotting ===\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='black', s=20)\n",
        "\n",
        "for part, connections in anatomical_connections.items():\n",
        "    for i, j in connections:\n",
        "        if i < len(points) and j < len(points):  # ensure valid index\n",
        "            ax.plot(\n",
        "                [points[i, 0], points[j, 0]],\n",
        "                [points[i, 1], points[j, 1]],\n",
        "                [points[i, 2], points[j, 2]],\n",
        "                color=colors[part], linewidth=2\n",
        "            )\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title(f\"3D Skeleton - Frame {frame_idx} - {first_video}\")\n",
        "ax.view_init(elev=20, azim=-70)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IUkWt7Mtnpxz",
        "outputId": "0f3cc873-7280-4249-dcf1-48f12fc0216d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-444d9bee55b9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Select one example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mfirst_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_keypoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mfirst_video\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst_action\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}