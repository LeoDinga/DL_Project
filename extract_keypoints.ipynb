{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeoDinga/DL_Project/blob/main/extract_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python tqdm --upgrade\n",
        "import os\n",
        "# os.kill(os.getpid(), 9)  # Reinicia o runtime para aplicar as mudanças"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM30w6NLpUuh",
        "outputId": "ad6ccdb9-11e3-4050-84ec-6720479ad4b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.15.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp311-cp311-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: protobuf, numpy, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.21 numpy-1.26.4 protobuf-4.25.8 sounddevice-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!git clone https://github.com/LeoDinga/DL_Project.git\n",
        "%cd DL_Project\n"
      ],
      "metadata": {
        "id": "QpT9Hqfrb1Q6",
        "outputId": "654e2e1a-d097-4172-9136-2f7bc769eed6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_Project'...\n",
            "remote: Enumerating objects: 285, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 285 (delta 65), reused 12 (delta 5), pack-reused 130 (from 1)\u001b[K\n",
            "Receiving objects: 100% (285/285), 34.77 MiB | 24.04 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n",
            "/content/DL_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyLRUvlxoG4B",
        "outputId": "55954a00-634b-4d86-a695-b34e4eaff1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: VID-20250526-WA0012.mp4\n",
            "Processing: VID-20250526-WA0002.mp4\n",
            "Processing: VID-20250526-WA0011.mp4\n",
            "Processing: VID-20250526-WA0005.mp4\n",
            "Processing: VID-20250526-WA0008.mp4\n",
            "Processing: VID-20250526-WA0010.mp4\n",
            "Processing: VID-20250526-WA0009.mp4\n",
            "Processing: VID-20250526-WA0004.mp4\n",
            "Processing: VID-20250526-WA0007.mp4\n",
            "Processing: VID-20250526-WA0001.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing videos: 100%|██████████| 10/10 [00:52<00:00,  5.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keypoints saved to our_keypoints.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "def convert_video_to_npy(video_path, resize_shape=(224, 224)):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Error opening video file: {video_path}\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_resized = cv2.resize(frame, resize_shape)\n",
        "        frames.append(frame_resized)\n",
        "\n",
        "    cap.release()\n",
        "    return np.array(frames)\n",
        "\n",
        "def create_npy_from_videos_flat(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "\n",
        "    for video_file in os.listdir(src_dir):\n",
        "        if not video_file.lower().endswith((\".mp4\", \".avi\")):\n",
        "            continue\n",
        "\n",
        "        video_path = os.path.join(src_dir, video_file)\n",
        "        output_path = os.path.join(npy_dir, video_file.replace(\".mp4\", \".npy\").replace(\".avi\", \".npy\"))\n",
        "\n",
        "        try:\n",
        "            print(f\"Processing: {video_file}\")\n",
        "            frames_array = convert_video_to_npy(video_path)\n",
        "            np.save(output_path, frames_array)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "\n",
        "def pad_or_truncate_keypoints(keypoints, target_length=120):\n",
        "    num_frames = keypoints.shape[0]\n",
        "    if num_frames < target_length:\n",
        "        padding = np.zeros((target_length - num_frames, keypoints.shape[1], keypoints.shape[2]))\n",
        "        return np.concatenate((keypoints, padding), axis=0)\n",
        "    else:\n",
        "        return keypoints[:target_length]\n",
        "\n",
        "def create_npy_from_videos(src_dir, npy_dir):\n",
        "    os.makedirs(npy_dir, exist_ok=True)\n",
        "    for action in os.listdir(src_dir):\n",
        "        action_path = os.path.join(src_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "        dest_action_path = os.path.join(npy_dir, action)\n",
        "        os.makedirs(dest_action_path, exist_ok=True)\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if file.endswith((\".avi\", \".mp4\")):\n",
        "                video_path = os.path.join(action_path, video_file)\n",
        "                output_path = os.path.join(dest_action_path, video_file.replace(\".avi\", \".npy\"))\n",
        "                try:\n",
        "                    frames_array = convert_video_to_npy(video_path)\n",
        "                    np.save(output_path, frames_array)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "def extract_keypoints_from_npy(npy_dir, save_path=\"our_keypoints.npz\"):\n",
        "    mp_pose = mp.solutions.pose\n",
        "    pose = mp_pose.Pose(static_image_mode=True)\n",
        "    all_keypoints = {}\n",
        "\n",
        "    for action in tqdm(os.listdir(npy_dir), desc=\"Processing actions\"):\n",
        "        action_path = os.path.join(npy_dir, action)\n",
        "        if not os.path.isdir(action_path):\n",
        "            continue\n",
        "\n",
        "        all_keypoints[action] = {}\n",
        "        for video_file in os.listdir(action_path):\n",
        "            if not video_file.endswith(\".npy\"):\n",
        "                continue\n",
        "            video_path = os.path.join(action_path, video_file)\n",
        "            try:\n",
        "                sample = np.load(video_path)\n",
        "                if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "                    continue\n",
        "                sample = sample.astype(np.uint8)\n",
        "\n",
        "                video_keypoints = []\n",
        "                for frame in sample[:]:\n",
        "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                    results = pose.process(frame_rgb)\n",
        "                    if results.pose_landmarks:\n",
        "                        keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "                    else:\n",
        "                        keypoints = np.zeros((33, 3)).tolist()\n",
        "                    video_keypoints.append(keypoints)\n",
        "\n",
        "                if video_keypoints:\n",
        "                    kp_array = np.array(video_keypoints)\n",
        "                    kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "                    all_keypoints[action][video_file] = kp_array\n",
        "            except Exception as e:\n",
        "                print(f\"Error with {video_file}: {e}\")\n",
        "\n",
        "    # Transformar em dicionário plano para salvar com np.savez_compressed\n",
        "    flat_dict = {}\n",
        "    for action, videos in all_keypoints.items():\n",
        "        for video_file, arr in videos.items():\n",
        "            key = f\"{action}__{video_file.replace('.npy', '')}\"\n",
        "            flat_dict[key] = arr\n",
        "\n",
        "    np.savez_compressed(save_path, **flat_dict)\n",
        "    print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "def extract_keypoints_from_npy_flat(npy_dir, save_path=\"our_keypoints.npz\"):\n",
        "\n",
        "  mp_pose = mp.solutions.pose\n",
        "  pose = mp_pose.Pose(\n",
        "      static_image_mode=False,\n",
        "      min_detection_confidence=0.3,\n",
        "      min_tracking_confidence=0.3\n",
        "  )\n",
        "\n",
        "  all_keypoints = {}\n",
        "\n",
        "  for video_file in tqdm(os.listdir(npy_dir), desc=\"Processing videos\"):\n",
        "      if not video_file.endswith(\".npy\"):\n",
        "          continue\n",
        "      video_path = os.path.join(npy_dir, video_file)\n",
        "      try:\n",
        "          sample = np.load(video_path)\n",
        "          if sample.ndim != 4 or sample.shape[-1] != 3:\n",
        "              print(f\"Skipping {video_file}, unexpected shape {sample.shape}\")\n",
        "              continue\n",
        "          sample = sample.astype(np.uint8)\n",
        "\n",
        "          video_keypoints = []\n",
        "          for frame in sample:\n",
        "              frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "              results = pose.process(frame_rgb)\n",
        "              if results.pose_landmarks:\n",
        "                  keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]\n",
        "              else:\n",
        "                  keypoints = np.zeros((33, 3)).tolist()\n",
        "              video_keypoints.append(keypoints)\n",
        "\n",
        "          if video_keypoints:\n",
        "              kp_array = np.array(video_keypoints)\n",
        "              kp_array = pad_or_truncate_keypoints(kp_array, target_length=120)\n",
        "              kp_array = np.expand_dims(kp_array, axis=1)\n",
        "              key = video_file.replace(\".npy\", \"\")\n",
        "              all_keypoints[key] = kp_array\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing {video_file}: {e}\")\n",
        "\n",
        "  np.savez_compressed(save_path, **all_keypoints)\n",
        "  print(f\"Keypoints saved to {save_path}\")\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Clone dataset se necessário\n",
        "#     if not os.path.exists(\"dataset\"):\n",
        "#         os.system(\"git clone --filter=blob:none --no-checkout https://github.com/THETIS-dataset/dataset.git\")\n",
        "#         os.chdir(\"dataset\")\n",
        "#         os.system(\"git sparse-checkout init --cone\")\n",
        "#         os.system(\"git sparse-checkout set VIDEO_RGB\")\n",
        "#         os.system(\"git checkout\")\n",
        "#         os.chdir(\"..\")\n",
        "\n",
        "src_dir = \"/content/DL_Project/our_videos\"\n",
        "npy_dir = \"npy_videos\"\n",
        "\n",
        "create_npy_from_videos_flat(src_dir, npy_dir)\n",
        "extract_keypoints_from_npy_flat(npy_dir, save_path=\"our_keypoints.npz\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Carrega o ficheiro .npz\n",
        "data = np.load(\"our_keypoints.npz\")\n",
        "\n",
        "# Lista todas as chaves (nome de cada item salvo)\n",
        "print(\"Chaves no ficheiro npz:\")\n",
        "print(data.files)\n",
        "\n",
        "# Examina uma chave específica (por exemplo, a primeira)\n",
        "first_key = data.files[0]\n",
        "print(f\"\\nShape dos dados da primeira chave '{first_key}':\")\n",
        "print(data[first_key].shape)\n",
        "\n",
        "print()\n",
        "\n",
        "print(data[first_key][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioXvYVsK7gnS",
        "outputId": "d2bcf552-fec6-4fa0-e5eb-1424cf9f4716"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chaves no ficheiro npz:\n",
            "['VID-20250526-WA0002', 'VID-20250526-WA0012', 'VID-20250526-WA0007', 'VID-20250526-WA0010', 'VID-20250526-WA0005', 'VID-20250526-WA0011', 'VID-20250526-WA0004', 'VID-20250526-WA0009', 'VID-20250526-WA0008', 'VID-20250526-WA0001']\n",
            "\n",
            "Shape dos dados da primeira chave 'VID-20250526-WA0002':\n",
            "(120, 1, 33, 3)\n",
            "\n",
            "[[[ 0.42431399  0.34511876 -0.16242044]\n",
            "  [ 0.41703218  0.33559465 -0.14940841]\n",
            "  [ 0.41620025  0.33553138 -0.14947633]\n",
            "  [ 0.41518393  0.33548069 -0.14952862]\n",
            "  [ 0.41586271  0.33641452 -0.18359487]\n",
            "  [ 0.41428122  0.33694866 -0.18359771]\n",
            "  [ 0.41250199  0.33753109 -0.18367767]\n",
            "  [ 0.4041788   0.34174848 -0.07311164]\n",
            "  [ 0.40090039  0.34496692 -0.22657399]\n",
            "  [ 0.42284408  0.35328954 -0.12938932]\n",
            "  [ 0.42063469  0.35384107 -0.17369001]\n",
            "  [ 0.40761331  0.38469881  0.04837427]\n",
            "  [ 0.39827815  0.38883004 -0.28051117]\n",
            "  [ 0.45567179  0.42478576  0.08975907]\n",
            "  [ 0.45202741  0.4388012  -0.33356792]\n",
            "  [ 0.51837987  0.43843904 -0.00121642]\n",
            "  [ 0.52236485  0.4428288  -0.3727842 ]\n",
            "  [ 0.53599596  0.4322497  -0.01401625]\n",
            "  [ 0.54091334  0.44706795 -0.4192085 ]\n",
            "  [ 0.54131949  0.42781705 -0.04425681]\n",
            "  [ 0.54402894  0.44003963 -0.41302428]\n",
            "  [ 0.5336259   0.43522635 -0.01825636]\n",
            "  [ 0.53890413  0.43926406 -0.37122026]\n",
            "  [ 0.39261594  0.49673539  0.10433805]\n",
            "  [ 0.4046416   0.50160819 -0.10447204]\n",
            "  [ 0.40349245  0.55055362  0.3086783 ]\n",
            "  [ 0.44290337  0.55013609 -0.15718183]\n",
            "  [ 0.36767054  0.60385978  0.55517793]\n",
            "  [ 0.43208537  0.6435048  -0.11164262]\n",
            "  [ 0.35684547  0.6121155   0.57913238]\n",
            "  [ 0.42177081  0.65986282 -0.10948955]\n",
            "  [ 0.38465768  0.6198498   0.55953228]\n",
            "  [ 0.48153996  0.65517598 -0.18758833]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_root = \"/content/DL_Project/our_videos\"\n",
        "print(\"Contents of root video folder:\")\n",
        "print(os.listdir(video_root))"
      ],
      "metadata": {
        "id": "8mSuJtuqmKK1",
        "outputId": "312c109e-9c8a-4de0-fa84-ff75eabf6ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of root video folder:\n",
            "['test_labels.txt', 'VID-20250526-WA0012.mp4', 'VID-20250526-WA0002.mp4', 'VID-20250526-WA0011.mp4', 'VID-20250526-WA0005.mp4', 'VID-20250526-WA0008.mp4', 'VID-20250526-WA0010.mp4', 'VID-20250526-WA0009.mp4', 'VID-20250526-WA0004.mp4', 'VID-20250526-WA0007.mp4', 'VID-20250526-WA0001.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Load keypoints\n",
        "keypoints_path = \"/content/our_keypoints.npz\"\n",
        "data = np.load(keypoints_path)\n",
        "\n",
        "# Rebuild dictionary\n",
        "all_keypoints = {}\n",
        "for key in data.files:\n",
        "    action, video_file = key.split(\"__\", 1)\n",
        "    if action not in all_keypoints:\n",
        "        all_keypoints[action] = {}\n",
        "    all_keypoints[action][video_file] = data[key]\n",
        "\n",
        "# Select one example\n",
        "first_action = list(all_keypoints.keys())[0]\n",
        "first_video = list(all_keypoints[first_action].keys())[0]\n",
        "frame_idx = 0\n",
        "\n",
        "points = all_keypoints[first_action][first_video][frame_idx]  # shape: (num_joints, 3)\n",
        "\n",
        "# === Define anatomical connections and colors ===\n",
        "anatomical_connections = {\n",
        "    'head': [\n",
        "        (0, 1), (1, 2), (2, 3),\n",
        "        (0, 4), (4, 5), (5, 6),\n",
        "        (3, 7), (6, 8),\n",
        "        (0, 9), (9, 10)\n",
        "    ],\n",
        "    'left_arm': [(11, 13), (13, 15), (15, 17), (15, 19), (15, 21)],\n",
        "    'right_arm': [(12, 14), (14, 16), (16, 18), (16, 20), (16, 22)],\n",
        "    'torso': [(11, 12), (23, 24), (11, 23), (12, 24)],\n",
        "    'left_leg': [(23, 25), (25, 27), (27, 29), (29, 31)],\n",
        "    'right_leg': [(24, 26), (26, 28), (28, 30), (30, 32)],\n",
        "}\n",
        "\n",
        "colors = {\n",
        "    'head': 'gray',\n",
        "    'left_arm': 'red',\n",
        "    'right_arm': 'blue',\n",
        "    'torso': 'orange',\n",
        "    'left_leg': 'green',\n",
        "    'right_leg': 'purple',\n",
        "}\n",
        "\n",
        "# === Plotting ===\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(points[:, 0], points[:, 1], points[:, 2], c='black', s=20)\n",
        "\n",
        "for part, connections in anatomical_connections.items():\n",
        "    for i, j in connections:\n",
        "        if i < len(points) and j < len(points):  # ensure valid index\n",
        "            ax.plot(\n",
        "                [points[i, 0], points[j, 0]],\n",
        "                [points[i, 1], points[j, 1]],\n",
        "                [points[i, 2], points[j, 2]],\n",
        "                color=colors[part], linewidth=2\n",
        "            )\n",
        "\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "ax.set_title(f\"3D Skeleton - Frame {frame_idx} - {first_video}\")\n",
        "ax.view_init(elev=20, azim=-70)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IUkWt7Mtnpxz",
        "outputId": "7bca808a-565a-449a-c749-5f6cc74fccda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 2, got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bbf24e831281>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mall_keypoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_keypoints\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mall_keypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "ntu_joints_in_mediapipe = [\n",
        "    0, 11, 12, 13, 14, 15, 16,\n",
        "    23, 24, 25, 26, 27, 28,\n",
        "    5, 2, 7, 8,\n",
        "    17, 18, 19, 20, 21, 22,\n",
        "    29, 30\n",
        "]\n",
        "\n",
        "def filter_to_ntu_joints(keypoints): # keypoints (T, 33, C)\n",
        "    return keypoints[:, ntu_joints_in_mediapipe, :]\n",
        "\n",
        "def prepare_stgcn_data(dataset, label_map):\n",
        "    data_list = []\n",
        "    for i, (keypoints, action_name) in enumerate(dataset):\n",
        "        keypoints = np.array(keypoints)  # (T, 33, C)\n",
        "        keypoints = filter_to_ntu_joints(keypoints)  # (T, 25, C)\n",
        "        num_frames, num_joints, channels = keypoints.shape\n",
        "        keypoints = keypoints[np.newaxis, ...]  # add person dim: (M=1, T, V, C)\n",
        "\n",
        "        sample = {\n",
        "            'frame_dir': f'sample_{i}',\n",
        "            'label': label_map[action_name],\n",
        "            'img_shape': None,\n",
        "            'total_frames': num_frames,\n",
        "            'keypoint': keypoints,\n",
        "        }\n",
        "        data_list.append(sample)\n",
        "    return data_list\n",
        "\n",
        "# Load your data\n",
        "data_npz = np.load(\"our_keypoints.npz\")\n",
        "dataset = []\n",
        "\n",
        "for key in data_npz.files:\n",
        "    keypoints = data_npz[key]\n",
        "    if keypoints.ndim == 4 and keypoints.shape[1] == 1:\n",
        "        keypoints = np.squeeze(keypoints, axis=1)\n",
        "    dataset.append((keypoints, \"unknown\"))\n",
        "\n",
        "label_map = {\"unknown\": 0}\n",
        "test_data = prepare_stgcn_data(dataset, label_map)\n",
        "\n",
        "with open(\"our_test_labels.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_data, f)\n",
        "\n",
        "print(f\"Created our_test_labels.pkl with {len(test_data)} samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPRqOJOPvvxx",
        "outputId": "b6b70f8a-5b5d-45fb-bb3b-076168b85147"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created our_test_labels.pkl with 10 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#novo\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "ntu_joints_in_mediapipe = [\n",
        "    0, 11, 12, 13, 14, 15, 16,\n",
        "    23, 24, 25, 26, 27, 28,\n",
        "    5, 2, 7, 8,\n",
        "    17, 18, 19, 20, 21, 22,\n",
        "    29, 30\n",
        "]\n",
        "\n",
        "def filter_to_ntu_joints(keypoints):\n",
        "    return keypoints[:, ntu_joints_in_mediapipe, :]\n",
        "\n",
        "def prepare_stgcn_data(dataset):\n",
        "    data_list = []\n",
        "    for i, (keypoints, label) in enumerate(dataset):\n",
        "        keypoints = np.array(keypoints)\n",
        "        keypoints = filter_to_ntu_joints(keypoints)\n",
        "        num_frames, num_joints, channels = keypoints.shape\n",
        "        keypoints = keypoints[np.newaxis, ...]  # add person dim: (M=1, T, V, C)\n",
        "\n",
        "        sample = {\n",
        "            'frame_dir': f'sample_{i}',\n",
        "            'label': int(label),  # usa o label verdadeiro como inteiro\n",
        "            'img_shape': None,\n",
        "            'total_frames': num_frames,\n",
        "            'keypoint': keypoints,\n",
        "        }\n",
        "        data_list.append(sample)\n",
        "    return data_list\n",
        "\n",
        "# === Etapa 1: Ler labels do ficheiro ===\n",
        "label_file_path = \"test_labels.txt\"\n",
        "video_to_label = {}\n",
        "\n",
        "with open(label_file_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        video_name, label = line.strip().split()\n",
        "        video_name = os.path.splitext(video_name)[0]  # remove .mp4\n",
        "        video_to_label[video_name] = label  # mantém como string (ou converte já aqui para int)\n",
        "\n",
        "# === Etapa 2: Carregar dados ===\n",
        "data_npz = np.load(\"our_keypoints.npz\")\n",
        "dataset = []\n",
        "\n",
        "for key in data_npz.files:\n",
        "    video_name = key  # já está sem .mp4\n",
        "    if video_name in video_to_label:\n",
        "        keypoints = data_npz[key]\n",
        "        if keypoints.ndim == 4 and keypoints.shape[1] == 1:\n",
        "            keypoints = np.squeeze(keypoints, axis=1)\n",
        "        dataset.append((keypoints, video_to_label[video_name]))\n",
        "    else:\n",
        "        print(f\"Aviso: {video_name} não tem label, será ignorado.\")\n",
        "\n",
        "# === Etapa 3: Preparar e guardar ===\n",
        "test_data = prepare_stgcn_data(dataset)\n",
        "\n",
        "with open(\"our_test_labels.pkl\", \"wb\") as f:\n",
        "    pickle.dump(test_data, f)\n",
        "\n",
        "print(f\"Created our_test_labels.pkl with {len(test_data)} samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpaqEnCZ9jUb",
        "outputId": "04dda4bc-2157-49ff-ba82-e9d5f7ff713e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created our_test_labels.pkl with 10 samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testess"
      ],
      "metadata": {
        "id": "-7qfhb97ARzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"our_test_labels.pkl\", \"rb\") as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "print(f\"Total de amostras: {len(data)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2dFPqj_ASwU",
        "outputId": "0cea43c3-a3dd-446e-f377-89b371653750"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de amostras: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar as primeiras 3 amostras\n",
        "for i, sample in enumerate(data[:3]):\n",
        "    print(f\"\\n--- Sample {i} ---\")\n",
        "    print(\"Frame dir:\", sample['frame_dir'])\n",
        "    print(\"Label:\", sample['label'])\n",
        "    print(\"Total frames:\", sample['total_frames'])\n",
        "    print(\"Keypoint shape:\", sample['keypoint'].shape)  # Deve ser (1, T, 25, 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoTlpxn3ATiW",
        "outputId": "00a8abfb-3ffa-4d02-a830-060efd764f8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 0 ---\n",
            "Frame dir: sample_0\n",
            "Label: 1\n",
            "Total frames: 120\n",
            "Keypoint shape: (1, 120, 25, 3)\n",
            "\n",
            "--- Sample 1 ---\n",
            "Frame dir: sample_1\n",
            "Label: 1\n",
            "Total frames: 120\n",
            "Keypoint shape: (1, 120, 25, 3)\n",
            "\n",
            "--- Sample 2 ---\n",
            "Frame dir: sample_2\n",
            "Label: 4\n",
            "Total frames: 120\n",
            "Keypoint shape: (1, 120, 25, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [sample['label'] for sample in data]\n",
        "print(\"Labels únicas encontradas:\", sorted(set(labels)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KgxrOOoAVq1",
        "outputId": "44dcbb7f-4380-487a-98bd-7ec403dd0bcb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels únicas encontradas: [1, 4, 5, 6]\n"
          ]
        }
      ]
    }
  ]
}